{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis\n",
    "\n",
    "In this notebook we plot the patch assessement metrics, and other useful ones from the patch evaluation journey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by loading the results.\n",
    "\n",
    "Note that we remove three bugs (Math-28, Math-44, JacksonDatabind-82) from the results since the function they change is included in Megadiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_jsonl_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        bugs = [json.loads(line) for line in f]\n",
    "\n",
    "    # Keep only bugs in the single-function benchmarks\n",
    "    defects4j_sf_bugs = \"../../results/benchmarks/defects4j_sf.txt\"\n",
    "    with open(defects4j_sf_bugs, \"r\") as f:\n",
    "        sf_bugs = set([line.strip() for line in f.readlines()])\n",
    "    humanevaljava_sf_bugs = \"../../results/benchmarks/humanevaljava_sf.txt\"\n",
    "    with open(humanevaljava_sf_bugs, \"r\") as f:\n",
    "        sf_bugs.update([line.strip() for line in f.readlines()])\n",
    "\n",
    "    bugs = [bug for bug in bugs if bug[\"identifier\"] in sf_bugs]\n",
    "\n",
    "    # Remove bugs that might be leaked by Megadiff\n",
    "    to_remove = [\"Math-28\", \"Math-44\", \"JacksonDatabind-82\"]\n",
    "    bugs = [bug for bug in bugs if bug[\"identifier\"] not in to_remove]\n",
    "\n",
    "    return bugs\n",
    "\n",
    "def read_multi_loc_bugs(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        bugs = set([line.strip() for line in f.readlines()])\n",
    "    return bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the results we present in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Model    Repr      Benchmark  Total  Plausible  Semantical  AST  Exact  Correct Multi-loc\n",
      "      codellama ir3_or2      Defects4J    478        131          83   70     52                 14\n",
      "  codellama-ir4 ir4_or2      Defects4J    476        107          69   60     50                  7\n",
      "          gpt35     gpt      Defects4J    483         71          45   33     23                 11\n",
      "           gpt4     gpt      Defects4J    483        119          72   60     47                 20\n",
      "    repairllama ir1_or1      Defects4J    476         79          45   31     29                  7\n",
      "    repairllama ir1_or3      Defects4J    476         41          24   17     15                  6\n",
      "    repairllama ir1_or4      Defects4J    477         12           3    2      2                  0\n",
      "    repairllama ir2_or2      Defects4J    477        198         139  122    121                 32\n",
      "    repairllama ir3_or2      Defects4J    480        153         102   86     83                 13\n",
      "    repairllama ir4_or2      Defects4J    477        195         144  125    124                 35\n",
      "repairllama-fft ir4_or2      Defects4J    476        146          98   84     66                 11\n",
      "      codellama ir3_or2 HumanEval-Java    162        107         103   81     71                 11\n",
      "  codellama-ir4 ir4_or2 HumanEval-Java    162         95          91   72     65                  5\n",
      "          gpt35     gpt HumanEval-Java    162        107          97   63     50                 12\n",
      "           gpt4     gpt HumanEval-Java    162        124         116   74     64                 15\n",
      "    repairllama ir1_or1 HumanEval-Java    162         78          72   54     52                  8\n",
      "    repairllama ir1_or3 HumanEval-Java    162         39          37   21     21                  2\n",
      "    repairllama ir1_or4 HumanEval-Java    162          5           4    2      2                  0\n",
      "    repairllama ir2_or2 HumanEval-Java    162        118         108   77     69                 12\n",
      "    repairllama ir3_or2 HumanEval-Java    162        103          99   68     63                 11\n",
      "    repairllama ir4_or2 HumanEval-Java    162        118         109   82     75                 13\n",
      "repairllama-fft ir4_or2 HumanEval-Java    162        109         100   83     74                 15\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def plot_table(experiments: List[Tuple[str, List[dict]]]):\n",
    "    # Plot a table with the results of each experiment\n",
    "    # The table has the following columns:\n",
    "    # - Model name\n",
    "    # - Representation\n",
    "    # - Benchmark\n",
    "    # - Number of bugs with an exact match fix\n",
    "    # - Number of bugs with a AST match fix\n",
    "    # - Number of bugs with a semantical match fix\n",
    "    # - Number of bugs with a plausible fix\n",
    "    # - Total number of bugs with patches\n",
    "\n",
    "    # Define the table data\n",
    "    data = []\n",
    "    multi_loc_bugs = read_multi_loc_bugs(\"multi-loc-bugs.txt\")\n",
    "    for file_path, bugs in experiments:\n",
    "        # Compute metrics\n",
    "        exact_match = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and (any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])))\n",
    "        ast_match = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and (\n",
    "            any(patch[\"ast_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])\n",
    "        ))\n",
    "        semantical_match = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and (\n",
    "           any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"ast_match\"] for patch in bug[\"evaluation\"])\n",
    "        ))\n",
    "        plausible = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and (\n",
    "            any(patch[\"test\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"ast_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in bug[\"evaluation\"])\n",
    "        ))\n",
    "        total = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None)\n",
    "        correct_multi_loc = sum(1 for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and bug[\"identifier\"] in multi_loc_bugs and (\n",
    "           any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"ast_match\"] for patch in bug[\"evaluation\"])\n",
    "        ))\n",
    "\n",
    "        # Extract meta-data from file_path\n",
    "        benchmark = \"Defects4J\" if \"defects4j\" in file_path else \"HumanEval-Java\"\n",
    "        model = \"repairllama-fft\" if \"repairllama-fft\" in file_path else \"repairllama\" if \"repairllama\" in file_path else \"gpt4\" if \"gpt4\" in file_path else \"gpt35\" if \"gpt35\" in file_path else \"codellama-ir4\" if \"codellama-ir4\" in file_path else \"codellama\"\n",
    "        pattern = r\"ir\\d+_or\\d+\"\n",
    "        ir_or = re.search(pattern, file_path)\n",
    "        if ir_or:\n",
    "            ir_or = ir_or.group()\n",
    "        representation = {\"gpt4\": \"gpt\", \"gpt35\": \"gpt\", \"repairllama\": ir_or, \"repairllama-fft\": \"ir4_or2\", \"codellama\": \"ir3_or2\", \"codellama-ir4\": \"ir4_or2\"}[model]\n",
    "\n",
    "        data.append([model, representation, benchmark, total, plausible, semantical_match, ast_match, exact_match, correct_multi_loc])\n",
    "\n",
    "    # Sort the data according to representation\n",
    "    data = sorted(data, key=lambda x: x[1])\n",
    "    # Sort the data according to model\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "    # Sort the data according to benchmark\n",
    "    data = sorted(data, key=lambda x: x[2])\n",
    "\n",
    "    # Show the table with pandas, do not split the table\n",
    "    df = pd.DataFrame(data, columns=[\"Model\", \"Repr\", \"Benchmark\", \"Total\", \"Plausible\", \"Semantical\", \"AST\", \"Exact\", \"Correct Multi-loc\"])\n",
    "    print(df.to_string(index=False))\n",
    "\n",
    "def plot_experiments(experiments_path: str):\n",
    "    experiments = []\n",
    "    for file_path in Path(experiments_path).glob(\"*.jsonl\"):\n",
    "        experiments.append((file_path.stem, read_jsonl_file(file_path)))\n",
    "\n",
    "    plot_table(experiments)\n",
    "\n",
    "plot_experiments(\"../../results/3_martin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical significant and effect size analysis\n",
    "\n",
    "We measure the statistical significance and effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "defects4j_set = set()\n",
    "humanevaljava_set = set()\n",
    "\n",
    "with open(\"../../results/benchmarks/defects4j_sf.txt\", \"r\") as f:\n",
    "    defects4j_set.update([line.strip() for line in f.readlines()])\n",
    "\n",
    "with open(\"../../results/benchmarks/humanevaljava_sf.txt\", \"r\") as f:\n",
    "    humanevaljava_set.update([line.strip() for line in f.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_df(experiments: List[Tuple[str, List[dict]]]):\n",
    "    # Generate a granular dataframe with the results of each experiment\n",
    "    # The table has the following columns:\n",
    "    # - Model name\n",
    "    # - Representation\n",
    "    # - Benchmark\n",
    "    # - Bitvector of bugs with an exact match fix\n",
    "    # - Bitvector of bugs with a AST match fix\n",
    "    # - Bitvector of bugs with a semantical match fix\n",
    "    # - Bitvector of bugs with a plausible fix\n",
    "\n",
    "    # Define the table data\n",
    "    data = []\n",
    "    multi_loc_bugs = read_multi_loc_bugs(\"multi-loc-bugs.txt\")\n",
    "    for file_path, bugs in experiments:\n",
    "        # Extract meta-data from file_path\n",
    "        benchmark = \"Defects4J\" if \"defects4j\" in file_path else \"HumanEval-Java\"\n",
    "        model = \"repairllama-fft\" if \"repairllama-fft\" in file_path else \"repairllama\" if \"repairllama\" in file_path else \"gpt4\" if \"gpt4\" in file_path else \"gpt35\" if \"gpt35\" in file_path else \"codellama-ir4\" if \"codellama-ir4\" in file_path else \"codellama\"\n",
    "        pattern = r\"ir\\d+_or\\d+\"\n",
    "        ir_or = re.search(pattern, file_path)\n",
    "        if ir_or:\n",
    "            ir_or = ir_or.group()\n",
    "        representation = {\"gpt4\": \"gpt\", \"gpt35\": \"gpt\", \"repairllama\": ir_or, \"repairllama-fft\": \"ir4_or2\", \"codellama\": \"ir3_or2\", \"codellama-ir4\": \"ir4_or2\"}[model]\n",
    "\n",
    "        # Bitvector index\n",
    "        index = defects4j_set if benchmark == \"Defects4J\" else humanevaljava_set\n",
    "\n",
    "        # Compute bitvectors\n",
    "        exp_df = pd.DataFrame(bugs)\n",
    "        exact_match = []\n",
    "        ast_match = []\n",
    "        semantical_match = []\n",
    "        plausible = []\n",
    "\n",
    "        for bug in index:\n",
    "            bug_df = exp_df[exp_df[\"identifier\"] == bug]\n",
    "            if bug_df.empty or \"evaluation\" not in bug_df or bug_df[\"evaluation\"].values[0] is None:\n",
    "                exact_match.append(False)\n",
    "                ast_match.append(False)\n",
    "                semantical_match.append(False)\n",
    "                plausible.append(False)\n",
    "            else:\n",
    "                evaluation = bug_df[\"evaluation\"].values[0]\n",
    "\n",
    "                exact_match.append(any(patch[\"exact_match\"] for patch in evaluation))\n",
    "                ast_match.append(any(patch[\"ast_match\"] for patch in evaluation) \n",
    "                                 or any(patch[\"exact_match\"] for patch in evaluation))\n",
    "                semantical_match.append(any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in evaluation) \n",
    "                                        or any(patch[\"exact_match\"] for patch in evaluation) \n",
    "                                        or any(patch[\"ast_match\"] for patch in evaluation))\n",
    "                plausible.append(any(patch[\"test\"] for patch in evaluation) \n",
    "                                 or any(patch[\"exact_match\"] for patch in evaluation) \n",
    "                                 or any(patch[\"ast_match\"] for patch in evaluation) \n",
    "                                 or any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in evaluation))\n",
    "\n",
    "        data.append([model, representation, benchmark, plausible, semantical_match, ast_match, exact_match])\n",
    "\n",
    "    # Sort the data according to representation\n",
    "    data = sorted(data, key=lambda x: x[1])\n",
    "    # Sort the data according to model\n",
    "    data = sorted(data, key=lambda x: x[0])\n",
    "    # Sort the data according to benchmark\n",
    "    data = sorted(data, key=lambda x: x[2])\n",
    "\n",
    "    # Show the table with pandas, do not split the table\n",
    "    df = pd.DataFrame(data, columns=[\"Model\", \"Repr\", \"Benchmark\", \"Plausible\", \"Semantical\", \"AST\", \"Exact\"])\n",
    "    return df\n",
    "\n",
    "def generate_granular_df(experiments_path: str):\n",
    "    experiments = []\n",
    "    for file_path in Path(experiments_path).glob(\"*.jsonl\"):\n",
    "        experiments.append((file_path.stem, read_jsonl_file(file_path)))\n",
    "\n",
    "    return generate_df(experiments)\n",
    "\n",
    "experiments_df = generate_granular_df(\"../../results/3_martin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Exact for Defects4J\n",
      "Cochran's Q: 492.20, p-value: 0.0000\n",
      "Significance matrix (Exact)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt35 (gpt)               |                     1 |                         1 |             1 |            1 |                       0 |                       0 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir3_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir4_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           1 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "Effect size matrix (Exact)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |             0         |                 0.562231  |     0.3306    |    0.314978  |               0.250288  |               0.0539306 |               0.0818    |                0.416892 |               0.639125  |                0.4544   |                    0.54312  |\n",
      "| codellama-ir4 (ir4_or2)   |             0.562231  |                 0         |     0.371269  |    0.324894  |               0.458132  |               0.213876  |               0.0216743 |                0.447585 |               0.476552  |                0.454706 |                    0.755547 |\n",
      "| gpt35 (gpt)               |             0.3306    |                 0.371269  |     0         |    0.484594  |               0.312198  |               0.0724374 |               0.0142671 |                0.320149 |               0.285378  |                0.314413 |                    0.364445 |\n",
      "| gpt4 (gpt)                |             0.314978  |                 0.324894  |     0.484594  |    0         |               0.211738  |               0.143072  |               0.0209424 |                0.359444 |               0.369869  |                0.431694 |                    0.358349 |\n",
      "| repairllama (ir1_or1)     |             0.250288  |                 0.458132  |     0.312198  |    0.211738  |               0         |               0.206316  |               0.0161246 |                0.297254 |               0.23226   |                0.351021 |                    0.432833 |\n",
      "| repairllama (ir1_or3)     |             0.0539306 |                 0.213876  |     0.0724374 |    0.143072  |               0.206316  |               0         |               0.174404  |                0.310138 |               0.172177  |                0.277839 |                    0.207293 |\n",
      "| repairllama (ir1_or4)     |             0.0818    |                 0.0216743 |     0.0142671 |    0.0209424 |               0.0161246 |               0.174404  |               0         |                0.111722 |               0.0563321 |                0.10991  |                    0.162211 |\n",
      "| repairllama (ir2_or2)     |             0.416892  |                 0.447585  |     0.320149  |    0.359444  |               0.297254  |               0.310138  |               0.111722  |                0        |               0.61158   |                0.798481 |                    0.563857 |\n",
      "| repairllama (ir3_or2)     |             0.639125  |                 0.476552  |     0.285378  |    0.369869  |               0.23226   |               0.172177  |               0.0563321 |                0.61158  |               0         |                0.650341 |                    0.490814 |\n",
      "| repairllama (ir4_or2)     |             0.4544    |                 0.454706  |     0.314413  |    0.431694  |               0.351021  |               0.277839  |               0.10991   |                0.798481 |               0.650341  |                0        |                    0.567464 |\n",
      "| repairllama-fft (ir4_or2) |             0.54312   |                 0.755547  |     0.364445  |    0.358349  |               0.432833  |               0.207293  |               0.162211  |                0.563857 |               0.490814  |                0.567464 |                    0        |\n",
      "Analyzing AST for Defects4J\n",
      "Cochran's Q: 464.01, p-value: 0.0000\n",
      "Significance matrix (AST)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt35 (gpt)               |                     1 |                         1 |             1 |            1 |                       0 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir3_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           1 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "Effect size matrix (AST)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |             0         |                 0.523282  |     0.401996  |    0.363058  |               0.205011  |               0.0816654 |               0.0652543 |                0.492782 |               0.808042  |                0.563435 |                    0.525778 |\n",
      "| codellama-ir4 (ir4_or2)   |             0.523282  |                 0         |     0.445908  |    0.372897  |               0.465351  |               0.303219  |               0.0240188 |                0.489983 |               0.58021   |                0.523678 |                    0.688871 |\n",
      "| gpt35 (gpt)               |             0.401996  |                 0.445908  |     0         |    0.495612  |               0.331372  |               0.082355  |               0.0172762 |                0.372224 |               0.36807   |                0.365453 |                    0.439282 |\n",
      "| gpt4 (gpt)                |             0.363058  |                 0.372897  |     0.495612  |    0         |               0.286257  |               0.201124  |               0.0240188 |                0.389104 |               0.400052  |                0.452198 |                    0.374787 |\n",
      "| repairllama (ir1_or1)     |             0.205011  |                 0.465351  |     0.331372  |    0.286257  |               0         |               0.271252  |               0.0167078 |                0.29589  |               0.210293  |                0.347597 |                    0.415388 |\n",
      "| repairllama (ir1_or3)     |             0.0816654 |                 0.303219  |     0.082355  |    0.201124  |               0.271252  |               0         |               0.162738  |                0.277442 |               0.176105  |                0.272548 |                    0.239018 |\n",
      "| repairllama (ir1_or4)     |             0.0652543 |                 0.0240188 |     0.0172762 |    0.0240188 |               0.0167078 |               0.162738  |               0         |                0.111111 |               0.0545119 |                0.109319 |                    0.140685 |\n",
      "| repairllama (ir2_or2)     |             0.492782  |                 0.489983  |     0.372224  |    0.389104  |               0.29589   |               0.277442  |               0.111111  |                0        |               0.589971  |                0.799564 |                    0.651887 |\n",
      "| repairllama (ir3_or2)     |             0.808042  |                 0.58021   |     0.36807   |    0.400052  |               0.210293  |               0.176105  |               0.0545119 |                0.589971 |               0         |                0.628022 |                    0.572688 |\n",
      "| repairllama (ir4_or2)     |             0.563435  |                 0.523678  |     0.365453  |    0.452198  |               0.347597  |               0.272548  |               0.109319  |                0.799564 |               0.628022  |                0        |                    0.640251 |\n",
      "| repairllama-fft (ir4_or2) |             0.525778  |                 0.688871  |     0.439282  |    0.374787  |               0.415388  |               0.239018  |               0.140685  |                0.651887 |               0.572688  |                0.640251 |                    0        |\n",
      "Analyzing Semantical for Defects4J\n",
      "Cochran's Q: 488.56, p-value: 0.0000\n",
      "Significance matrix (Semantical)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt35 (gpt)               |                     1 |                         1 |             1 |            1 |                       0 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir3_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           1 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "Effect size matrix (Semantical)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |             0         |                 0.552023  |     0.345855  |    0.319186  |               0.232746  |                0.124045 |               0.0341743 |                0.475634 |               0.759927  |                0.54423  |                    0.549107 |\n",
      "| codellama-ir4 (ir4_or2)   |             0.552023  |                 0         |     0.419501  |    0.361846  |               0.460156  |                0.234074 |               0.0433255 |                0.473618 |               0.557998  |                0.498262 |                    0.677412 |\n",
      "| gpt35 (gpt)               |             0.345855  |                 0.419501  |     0         |    0.506476  |               0.339052  |                0.156783 |               0.0250665 |                0.395174 |               0.358727  |                0.399433 |                    0.352935 |\n",
      "| gpt4 (gpt)                |             0.319186  |                 0.361846  |     0.506476  |    0         |               0.326738  |                0.172587 |               0.0327197 |                0.403166 |               0.382988  |                0.478311 |                    0.353959 |\n",
      "| repairllama (ir1_or1)     |             0.232746  |                 0.460156  |     0.339052  |    0.326738  |               0         |                0.320547 |               0.0655443 |                0.348097 |               0.254214  |                0.399433 |                    0.405973 |\n",
      "| repairllama (ir1_or3)     |             0.124045  |                 0.234074  |     0.156783  |    0.172587  |               0.320547  |                0        |               0.224581  |                0.297385 |               0.186063  |                0.268405 |                    0.240808 |\n",
      "| repairllama (ir1_or4)     |             0.0341743 |                 0.0433255 |     0.0250665 |    0.0327197 |               0.0655443 |                0.224581 |               0         |                0.124622 |               0.0240462 |                0.121559 |                    0.156895 |\n",
      "| repairllama (ir2_or2)     |             0.475634  |                 0.473618  |     0.395174  |    0.403166  |               0.348097  |                0.297385 |               0.124622  |                0        |               0.580048  |                0.796233 |                    0.635637 |\n",
      "| repairllama (ir3_or2)     |             0.759927  |                 0.557998  |     0.358727  |    0.382988  |               0.254214  |                0.186063 |               0.0240462 |                0.580048 |               0         |                0.595618 |                    0.560016 |\n",
      "| repairllama (ir4_or2)     |             0.54423   |                 0.498262  |     0.399433  |    0.478311  |               0.399433  |                0.268405 |               0.121559  |                0.796233 |               0.595618  |                0        |                    0.617765 |\n",
      "| repairllama-fft (ir4_or2) |             0.549107  |                 0.677412  |     0.352935  |    0.353959  |               0.405973  |                0.240808 |               0.156895  |                0.635637 |               0.560016  |                0.617765 |                    0        |\n",
      "Analyzing Plausible for Defects4J\n",
      "Cochran's Q: 625.84, p-value: 0.0000\n",
      "Significance matrix (Plausible)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         1 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     1 |                         1 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt35 (gpt)               |                     1 |                         1 |             1 |            1 |                       0 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir3_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           1 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "Effect size matrix (Plausible)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |             0         |                  0.595432 |     0.340199  |   0.302119   |                0.185709 |                0.133248 |              0.0531075  |                0.488263 |               0.756808  |                0.525403 |                    0.583773 |\n",
      "| codellama-ir4 (ir4_or2)   |             0.595432  |                  0        |     0.385329  |   0.379557   |                0.399052 |                0.30369  |              0.139714   |                0.490056 |               0.581324  |                0.528262 |                    0.670473 |\n",
      "| gpt35 (gpt)               |             0.340199  |                  0.385329 |     0         |   0.455923   |                0.276209 |                0.147377 |              0.0279905  |                0.404691 |               0.397611  |                0.410878 |                    0.35231  |\n",
      "| gpt4 (gpt)                |             0.302119  |                  0.379557 |     0.455923  |   0          |                0.268643 |                0.189261 |              0.00227312 |                0.434587 |               0.387702  |                0.472025 |                    0.379329 |\n",
      "| repairllama (ir1_or1)     |             0.185709  |                  0.399052 |     0.276209  |   0.268643   |                0        |                0.368244 |              0.181667   |                0.384601 |               0.230617  |                0.413791 |                    0.332466 |\n",
      "| repairllama (ir1_or3)     |             0.133248  |                  0.30369  |     0.147377  |   0.189261   |                0.368244 |                0        |              0.238088   |                0.276266 |               0.16154   |                0.295836 |                    0.237681 |\n",
      "| repairllama (ir1_or4)     |             0.0531075 |                  0.139714 |     0.0279905 |   0.00227312 |                0.181667 |                0.238088 |              0          |                0.138264 |               0.0638205 |                0.140601 |                    0.127426 |\n",
      "| repairllama (ir2_or2)     |             0.488263  |                  0.490056 |     0.404691  |   0.434587   |                0.384601 |                0.276266 |              0.138264   |                0        |               0.584     |                0.799863 |                    0.599343 |\n",
      "| repairllama (ir3_or2)     |             0.756808  |                  0.581324 |     0.397611  |   0.387702   |                0.230617 |                0.16154  |              0.0638205  |                0.584    |               0         |                0.639026 |                    0.571308 |\n",
      "| repairllama (ir4_or2)     |             0.525403  |                  0.528262 |     0.410878  |   0.472025   |                0.413791 |                0.295836 |              0.140601   |                0.799863 |               0.639026  |                0        |                    0.590764 |\n",
      "| repairllama-fft (ir4_or2) |             0.583773  |                  0.670473 |     0.35231   |   0.379329   |                0.332466 |                0.237681 |              0.127426   |                0.599343 |               0.571308  |                0.590764 |                    0        |\n",
      "Analyzing Exact for HumanEval-Java\n",
      "Cochran's Q: 255.21, p-value: 0.0000\n",
      "Significance matrix (Exact)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             1 |            0 |                       0 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| gpt35 (gpt)               |                     1 |                         1 |             1 |            1 |                       0 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       0 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         0 |             0 |            0 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       0 |                       0 |                           0 |\n",
      "| repairllama (ir3_or2)     |                     0 |                         0 |             1 |            0 |                       0 |                       1 |                       1 |                       0 |                       1 |                       0 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       1 |                           0 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           1 |\n",
      "Effect size matrix (Exact)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |              0        |                  0.672931 |     0.487106  |     0.507713 |               0.431963  |                0.288758 |               0.126575  |                0.446811 |               0.749999  |                0.57709  |                    0.613587 |\n",
      "| codellama-ir4 (ir4_or2)   |              0.672931 |                  0        |     0.407267  |     0.523497 |               0.462252  |                0.396457 |               0.136579  |                0.466454 |               0.61283   |                0.528059 |                    0.690423 |\n",
      "| gpt35 (gpt)               |              0.487106 |                  0.407267 |     0         |     0.690123 |               0.542433  |                0.378679 |               0.0463151 |                0.424382 |               0.508636  |                0.451625 |                    0.487182 |\n",
      "| gpt4 (gpt)                |              0.507713 |                  0.523497 |     0.690123  |     0        |               0.472148  |                0.327188 |               0.13835   |                0.529627 |               0.57271   |                0.54117  |                    0.551724 |\n",
      "| repairllama (ir1_or1)     |              0.431963 |                  0.462252 |     0.542433  |     0.472148 |               0         |                0.443208 |               0.0428701 |                0.504086 |               0.427932  |                0.528379 |                    0.6436   |\n",
      "| repairllama (ir1_or3)     |              0.288758 |                  0.396457 |     0.378679  |     0.327188 |               0.443208  |                0        |               0.289704  |                0.262217 |               0.257597  |                0.34194  |                    0.383956 |\n",
      "| repairllama (ir1_or4)     |              0.126575 |                  0.136579 |     0.0463151 |     0.13835  |               0.0428701 |                0.289704 |               0         |                0.129799 |               0.0891883 |                0.120416 |                    0.121922 |\n",
      "| repairllama (ir2_or2)     |              0.446811 |                  0.466454 |     0.424382  |     0.529627 |               0.504086  |                0.262217 |               0.129799  |                0        |               0.465196  |                0.577211 |                    0.5634   |\n",
      "| repairllama (ir3_or2)     |              0.749999 |                  0.61283  |     0.508636  |     0.57271  |               0.427932  |                0.257597 |               0.0891883 |                0.465196 |               0         |                0.579837 |                    0.590301 |\n",
      "| repairllama (ir4_or2)     |              0.57709  |                  0.528059 |     0.451625  |     0.54117  |               0.528379  |                0.34194  |               0.120416  |                0.577211 |               0.579837  |                0        |                    0.66457  |\n",
      "| repairllama-fft (ir4_or2) |              0.613587 |                  0.690423 |     0.487182  |     0.551724 |               0.6436    |                0.383956 |               0.121922  |                0.5634   |               0.590301  |                0.66457  |                    0        |\n",
      "Analyzing AST for HumanEval-Java\n",
      "Cochran's Q: 306.07, p-value: 0.0000\n",
      "Significance matrix (AST)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       1 |                       0 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             0 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| gpt35 (gpt)               |                     1 |                         0 |             1 |            1 |                       0 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "| gpt4 (gpt)                |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       1 |                       0 |                       0 |                           0 |\n",
      "| repairllama (ir3_or2)     |                     1 |                         0 |             0 |            0 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir4_or2)     |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           0 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         0 |             1 |            0 |                       1 |                       1 |                       1 |                       0 |                       1 |                       0 |                           1 |\n",
      "Effect size matrix (AST)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |              0        |                  0.645975 |     0.468505  |     0.520466 |               0.445215  |                0.275659 |               0.111803  |                0.407905 |               0.775485  |                0.518558 |                    0.605123 |\n",
      "| codellama-ir4 (ir4_or2)   |              0.645975 |                  0        |     0.4332    |     0.551418 |               0.421637  |                0.394491 |               0.125     |                0.467108 |               0.648865  |                0.510746 |                    0.599228 |\n",
      "| gpt35 (gpt)               |              0.468505 |                  0.4332   |     0         |     0.69198  |               0.510355  |                0.295294 |               0.0254824 |                0.508519 |               0.553055  |                0.534671 |                    0.550274 |\n",
      "| gpt4 (gpt)                |              0.520466 |                  0.551418 |     0.69198   |     0        |               0.429362  |                0.273278 |               0.121922  |                0.61607  |               0.57597   |                0.533969 |                    0.522767 |\n",
      "| repairllama (ir1_or1)     |              0.445215 |                  0.421637 |     0.510355  |     0.429362 |               0         |                0.428825 |               0.0395285 |                0.533163 |               0.433374  |                0.515092 |                    0.611266 |\n",
      "| repairllama (ir1_or3)     |              0.275659 |                  0.394491 |     0.295294  |     0.273278 |               0.428825  |                0        |               0.289704  |                0.221478 |               0.230319  |                0.307672 |                    0.339743 |\n",
      "| repairllama (ir1_or4)     |              0.111803 |                  0.125    |     0.0254824 |     0.121922 |               0.0395285 |                0.289704 |               0         |                0.117468 |               0.0950923 |                0.110432 |                    0.109076 |\n",
      "| repairllama (ir2_or2)     |              0.407905 |                  0.467108 |     0.508519  |     0.61607  |               0.533163  |                0.221478 |               0.117468  |                0        |               0.442792  |                0.569249 |                    0.582354 |\n",
      "| repairllama (ir3_or2)     |              0.775485 |                  0.648865 |     0.553055  |     0.57597  |               0.433374  |                0.230319 |               0.0950923 |                0.442792 |               0         |                0.539885 |                    0.579551 |\n",
      "| repairllama (ir4_or2)     |              0.518558 |                  0.510746 |     0.534671  |     0.533969 |               0.515092  |                0.307672 |               0.110432  |                0.569249 |               0.539885  |                0        |                    0.641915 |\n",
      "| repairllama-fft (ir4_or2) |              0.605123 |                  0.599228 |     0.550274  |     0.522767 |               0.611266  |                0.339743 |               0.109076  |                0.582354 |               0.579551  |                0.641915 |                    0        |\n",
      "Analyzing Semantical for HumanEval-Java\n",
      "Cochran's Q: 442.68, p-value: 0.0000\n",
      "Significance matrix (Semantical)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             0 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           0 |\n",
      "| gpt35 (gpt)               |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| gpt4 (gpt)                |                     0 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     0 |                         1 |             0 |            0 |                       1 |                       1 |                       1 |                       1 |                       0 |                       0 |                           0 |\n",
      "| repairllama (ir3_or2)     |                     0 |                         0 |             0 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       0 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     0 |                         1 |             0 |            0 |                       1 |                       1 |                       1 |                       0 |                       0 |                       1 |                           0 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         0 |             0 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           1 |\n",
      "Effect size matrix (Semantical)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |              0        |                  0.572449 |      0.453477 |     0.433755 |                0.470418 |                0.28954  |               0.120423  |                0.471676 |               0.817188  |                0.456532 |                    0.538921 |\n",
      "| codellama-ir4 (ir4_or2)   |              0.572449 |                  0        |      0.444495 |     0.409427 |                0.46457  |                0.302756 |               0.140543  |                0.457445 |               0.54584   |                0.471238 |                    0.533089 |\n",
      "| gpt35 (gpt)               |              0.453477 |                  0.444495 |      0        |     0.741341 |                0.453386 |                0.205368 |               0.130248  |                0.489785 |               0.457828  |                0.529723 |                    0.495499 |\n",
      "| gpt4 (gpt)                |              0.433755 |                  0.409427 |      0.741341 |     0        |                0.370393 |                0.146946 |               0.100196  |                0.484002 |               0.39626   |                0.377873 |                    0.320943 |\n",
      "| repairllama (ir1_or1)     |              0.470418 |                  0.46457  |      0.453386 |     0.370393 |                0        |                0.430725 |               0.177892  |                0.474342 |               0.407718  |                0.438349 |                    0.576481 |\n",
      "| repairllama (ir1_or3)     |              0.28954  |                  0.302756 |      0.205368 |     0.146946 |                0.430725 |                0        |               0.292453  |                0.228745 |               0.283195  |                0.254014 |                    0.307382 |\n",
      "| repairllama (ir1_or4)     |              0.120423 |                  0.140543 |      0.130248 |     0.100196 |                0.177892 |                0.292453 |               0         |                0.112509 |               0.0453311 |                0.11095  |                    0.125284 |\n",
      "| repairllama (ir2_or2)     |              0.471676 |                  0.457445 |      0.489785 |     0.484002 |                0.474342 |                0.228745 |               0.112509  |                0        |               0.483494  |                0.623316 |                    0.440033 |\n",
      "| repairllama (ir3_or2)     |              0.817188 |                  0.54584  |      0.457828 |     0.39626  |                0.407718 |                0.283195 |               0.0453311 |                0.483494 |               0         |                0.57725  |                    0.544185 |\n",
      "| repairllama (ir4_or2)     |              0.456532 |                  0.471238 |      0.529723 |     0.377873 |                0.438349 |                0.254014 |               0.11095   |                0.623316 |               0.57725   |                0        |                    0.587826 |\n",
      "| repairllama-fft (ir4_or2) |              0.538921 |                  0.533089 |      0.495499 |     0.320943 |                0.576481 |                0.307382 |               0.125284  |                0.440033 |               0.544185  |                0.587826 |                    0        |\n",
      "Analyzing Plausible for HumanEval-Java\n",
      "Cochran's Q: 494.56, p-value: 0.0000\n",
      "Significance matrix (Plausible)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |                     1 |                         0 |             0 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| codellama-ir4 (ir4_or2)   |                     0 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       0 |                       1 |                           1 |\n",
      "| gpt35 (gpt)               |                     0 |                         0 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           0 |\n",
      "| gpt4 (gpt)                |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       0 |                       1 |                       0 |                           1 |\n",
      "| repairllama (ir1_or1)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or3)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir1_or4)     |                     1 |                         1 |             1 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           1 |\n",
      "| repairllama (ir2_or2)     |                     0 |                         1 |             0 |            0 |                       1 |                       1 |                       1 |                       1 |                       1 |                       0 |                           0 |\n",
      "| repairllama (ir3_or2)     |                     0 |                         0 |             0 |            1 |                       1 |                       1 |                       1 |                       1 |                       1 |                       1 |                           0 |\n",
      "| repairllama (ir4_or2)     |                     0 |                         1 |             0 |            0 |                       1 |                       1 |                       1 |                       0 |                       1 |                       1 |                           0 |\n",
      "| repairllama-fft (ir4_or2) |                     0 |                         1 |             0 |            1 |                       1 |                       1 |                       1 |                       0 |                       0 |                       0 |                           1 |\n",
      "Effect size matrix (Plausible)\n",
      "|                           |   codellama (ir3_or2) |   codellama-ir4 (ir4_or2) |   gpt35 (gpt) |   gpt4 (gpt) |   repairllama (ir1_or1) |   repairllama (ir1_or3) |   repairllama (ir1_or4) |   repairllama (ir2_or2) |   repairllama (ir3_or2) |   repairllama (ir4_or2) |   repairllama-fft (ir4_or2) |\n",
      "|:--------------------------|----------------------:|--------------------------:|--------------:|-------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|------------------------:|----------------------------:|\n",
      "| codellama (ir3_or2)       |             0         |                  0.536085 |      0.476975 |    0.402967  |                0.429983 |                0.28175  |               0.0525739 |                0.470724 |               0.86602   |                0.500032 |                   0.58363   |\n",
      "| codellama-ir4 (ir4_or2)   |             0.536085  |                  0        |      0.456677 |    0.363372  |                0.432963 |                0.26766  |               0.149869  |                0.38896  |               0.510505  |                0.445321 |                   0.563171  |\n",
      "| gpt35 (gpt)               |             0.476975  |                  0.456677 |      0        |    0.741368  |                0.456072 |                0.22077  |               0.127945  |                0.470724 |               0.486771  |                0.500032 |                   0.472495  |\n",
      "| gpt4 (gpt)                |             0.402967  |                  0.363372 |      0.741368 |    0         |                0.300197 |                0.141345 |               0.0987907 |                0.41527  |               0.398419  |                0.41527  |                   0.328133  |\n",
      "| repairllama (ir1_or1)     |             0.429983  |                  0.432963 |      0.456072 |    0.300197  |                0        |                0.439867 |               0.113762  |                0.366224 |               0.369887  |                0.394    |                   0.46129   |\n",
      "| repairllama (ir1_or3)     |             0.28175   |                  0.26766  |      0.22077  |    0.141345  |                0.439867 |                0        |               0.316924  |                0.181542 |               0.276152  |                0.278925 |                   0.269554  |\n",
      "| repairllama (ir1_or4)     |             0.0525739 |                  0.149869 |      0.127945 |    0.0987907 |                0.113762 |                0.316924 |               0         |                0.108973 |               0.0608937 |                0.108973 |                   0.0483672 |\n",
      "| repairllama (ir2_or2)     |             0.470724  |                  0.38896  |      0.470724 |    0.41527   |                0.366224 |                0.181542 |               0.108973  |                0        |               0.431896  |                0.65678  |                   0.432012  |\n",
      "| repairllama (ir3_or2)     |             0.86602   |                  0.510505 |      0.486771 |    0.398419  |                0.369887 |                0.276152 |               0.0608937 |                0.431896 |               0         |                0.518417 |                   0.538556  |\n",
      "| repairllama (ir4_or2)     |             0.500032  |                  0.445321 |      0.500032 |    0.41527   |                0.394    |                0.278925 |               0.108973  |                0.65678  |               0.518417  |                0        |                   0.579912  |\n",
      "| repairllama-fft (ir4_or2) |             0.58363   |                  0.563171 |      0.472495 |    0.328133  |                0.46129  |                0.269554 |               0.0483672 |                0.432012 |               0.538556  |                0.579912 |                   0         |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import cochrans_q, mcnemar\n",
    "from itertools import combinations\n",
    "\n",
    "def analyze_model_results(df, results_column='Semantical', benchmark=\"Defects4J\", alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis on binary results from multiple models and display results in a binary table.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing {results_column} for {benchmark}\")\n",
    "\n",
    "    # Keep only the benchmark we are interested in\n",
    "    df = df[df['Benchmark'] == benchmark]\n",
    "\n",
    "    # Extract binary vectors and build dataframe\n",
    "    ext_df = pd.DataFrame(np.vstack(df[results_column].values), index=df.index)\n",
    "\n",
    "    # Compute cochran's q\n",
    "    q_stat, q_p_value, _ = cochrans_q(ext_df.T, return_object=False)\n",
    "    print(f\"Cochran's Q: {q_stat:.2f}, p-value: {q_p_value:.4f}\")\n",
    "\n",
    "    # Create empty dataframe for p-values and effect size\n",
    "    p_values = np.zeros((len(df.index), len(df.index)))\n",
    "    effect_size = np.zeros((len(df.index), len(df.index)))\n",
    "    \n",
    "    # Compute mcnemar's tests\n",
    "    for i, j in combinations(df.index, 2):\n",
    "        cur_df = ext_df.T[[i, j]]\n",
    "\n",
    "        # Compute contingency table\n",
    "        a = sum(cur_df[i] & cur_df[j])\n",
    "        b = sum(~cur_df[i] & cur_df[j])\n",
    "        c = sum(cur_df[i] & ~cur_df[j])\n",
    "        d = sum(~cur_df[i] & ~cur_df[j])\n",
    "\n",
    "        # Compute mcnemar's test\n",
    "        bunch = mcnemar(np.array([[a, b], [c, d]]))\n",
    "        p_values[i - len(df.index), j - len(df.index)] = bunch.pvalue\n",
    "        p_values[j - len(df.index), i - len(df.index)] = bunch.pvalue\n",
    "\n",
    "        # Compute effect size (cohen's g)\n",
    "        g = np.sqrt((a*d - b*c)**2 / ((a+b)*(c+d)*(a+c)*(b+d)))\n",
    "        effect_size[i - len(df.index), j - len(df.index)] = g\n",
    "        effect_size[j - len(df.index), i - len(df.index)] = g\n",
    "\n",
    "    # Create binary significance matrix\n",
    "    sig_matrix = p_values < alpha\n",
    "    \n",
    "    # Create DataFrame for better visualization\n",
    "    model_names = [f\"{row['Model']} ({row['Repr']})\" for _, row in df.iterrows()]\n",
    "    sig_df = pd.DataFrame(sig_matrix, \n",
    "                         index=model_names,\n",
    "                         columns=model_names)\n",
    "    effect_size_df = pd.DataFrame(effect_size,\n",
    "                                  index=model_names,\n",
    "                                  columns=model_names)\n",
    "\n",
    "    # Print df as markdown table\n",
    "    print(f\"Significance matrix ({results_column})\")\n",
    "    print(sig_df.to_markdown())\n",
    "    print(f\"Effect size matrix ({results_column})\")\n",
    "    print(effect_size_df.to_markdown())\n",
    "\n",
    "analyze_model_results(experiments_df, \"Exact\", \"Defects4J\")\n",
    "analyze_model_results(experiments_df, \"AST\", \"Defects4J\")\n",
    "analyze_model_results(experiments_df, \"Semantical\", \"Defects4J\")\n",
    "analyze_model_results(experiments_df, \"Plausible\", \"Defects4J\")\n",
    "\n",
    "analyze_model_results(experiments_df, \"Exact\", \"HumanEval-Java\")\n",
    "analyze_model_results(experiments_df, \"AST\", \"HumanEval-Java\")\n",
    "analyze_model_results(experiments_df, \"Semantical\", \"HumanEval-Java\")\n",
    "analyze_model_results(experiments_df, \"Plausible\", \"HumanEval-Java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic equivalence assessement\n",
    "\n",
    "Another interesting thing to look at is the agreement between raters (Andr, Sen, Martin).\n",
    "\n",
    "The following process was adopted during manual patch assessement:\n",
    "1. Andr and Sen both analyse all plausible patches independently\n",
    "2. Andr and Sen's results are merged, with the patches whose assessement is not agreed upon being flagged\n",
    "3. Martin looks at the flagged patches and breaks the tie (note that if Martin selects one patch as equivalent, the possible remaining flagged patches in the same bug are skipped since they won't change the result)\n",
    "\n",
    "We now want to look at the agreement between:\n",
    "1. Andr and Sen (across all patches)\n",
    "2. Andr and Martin (across the patches Martin looked at)\n",
    "3. Sen and Martin (across the patches Martin looked at)\n",
    "\n",
    "For this we compute Cohen's kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "andre_experiments = {}\n",
    "for file_path in Path(\"../../results/1_andre\").glob(\"*.jsonl\"):\n",
    "    experiment_name = file_path.stem.replace(\"_andre\", \"\")\n",
    "    andre_experiments[experiment_name] = read_jsonl_file(file_path)\n",
    "\n",
    "sen_experiments = {}\n",
    "for file_path in Path(\"../../results/1_sen\").glob(\"*.jsonl\"):\n",
    "    experiment_name = file_path.stem.replace(\"_sen\", \"\")\n",
    "    sen_experiments[experiment_name] = read_jsonl_file(file_path)\n",
    "\n",
    "martin_experiments = {}\n",
    "for file_path in Path(\"../../results/3_martin\").glob(\"*.jsonl\"):\n",
    "    experiment_name = file_path.stem.replace(\"_martin\", \"\")\n",
    "    martin_experiments[experiment_name] = read_jsonl_file(file_path)\n",
    "\n",
    "# Ensure that the experiments are the same\n",
    "assert set(andre_experiments.keys()) == set(sen_experiments.keys()) == set(martin_experiments.keys())\n",
    "\n",
    "# We now need to match the experiments between raters. We want to get a single list with tuples of the form (experiment_andre, experiment_sen, experiment_martin, experiment_merged)\n",
    "experiments = []\n",
    "for experiment in andre_experiments.keys():\n",
    "    experiments.append((experiment, andre_experiments[experiment], sen_experiments[experiment], martin_experiments[experiment]))\n",
    "\n",
    "assert len(experiments) == 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patches evaluated by both Andr and Sen: 2547\n",
      "Kappa between Andr and Sen: 0.7021540700176891\n",
      "Raw agreement between Andr and Sen: 0.8511974872398901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def get_bug_labels_first_pass(bug):\n",
    "    labels = []\n",
    "    if \"evaluation\" in bug and bug[\"evaluation\"] != None:\n",
    "        # Skip bugs that were not evaluated\n",
    "        if any(x[\"exact_match\"] or x[\"ast_match\"] for x in bug[\"evaluation\"]) or not any(x[\"test\"] for x in bug[\"evaluation\"]):\n",
    "            return labels\n",
    "\n",
    "        for i, evaluation in enumerate(bug[\"evaluation\"]):\n",
    "            # Skip if the patch is not plausible\n",
    "            if not evaluation[\"test\"]:\n",
    "                continue\n",
    "\n",
    "            assert \"semantical_match\" in evaluation, f\"Missing semantical_match for {bug['identifier']}\"\n",
    "            labels.append((i, evaluation[\"semantical_match\"]))\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def get_labels_first_pass(exp_a, exp_b):\n",
    "    # Sort bugs by bug-id so we get the same order of labels for everyone\n",
    "    exp_a = sorted(exp_a, key=lambda x: x[\"identifier\"])\n",
    "    exp_b = sorted(exp_b, key=lambda x: x[\"identifier\"])\n",
    "\n",
    "    # Ensure they have the same bugs\n",
    "    assert len(exp_a) == len(exp_b), f\"Number of bugs do not match ({len(exp_a)} vs {len(exp_b)})\"\n",
    "    assert all(a[\"identifier\"] == b[\"identifier\"] for a, b in zip(exp_a, exp_b))\n",
    "\n",
    "    labels_a = []\n",
    "    labels_b = []\n",
    "    for bug_a, bug_b in zip(exp_a, exp_b):\n",
    "        labels_bug_a = get_bug_labels_first_pass(bug_a)\n",
    "        labels_bug_b = get_bug_labels_first_pass(bug_b)\n",
    "        if len(labels_bug_a) == len(labels_bug_b) and all([a[0] == b[0] for a, b in zip(labels_bug_a, labels_bug_b)]):\n",
    "            labels_a.extend([a[1] for a in labels_bug_a])\n",
    "            labels_b.extend([b[1] for b in labels_bug_b])\n",
    "        else:\n",
    "            # HACK: In some of Sen's files, the original evaluation did not include any exact_match or ast_match\n",
    "            # This means that the get_labels function_first_pass will return more patches than it should.\n",
    "            # To overcome this we only keep the patches that Andr looked at by removing the patches only Sen (potentially) looked at\n",
    "            labels_a.extend(labels_bug_a)\n",
    "            labels_b.extend([b[1] for b in labels_bug_b if b[0] in [a[0] for a in labels_bug_a]])\n",
    "\n",
    "    return labels_a, labels_b\n",
    "\n",
    "def compute_kappa(experiments):\n",
    "    # First look at the agreement between Andr and Sen\n",
    "    andre_labels = []\n",
    "    sen_labels = []\n",
    "\n",
    "    # We will only consider bugs that have been evaluated by both Andr and Sen\n",
    "    for experiment, andre_experiment, sen_experiment, _ in experiments:\n",
    "        # print(f\"Computing kappa for {experiment}\")\n",
    "        labels_a, labels_b = get_labels_first_pass(andre_experiment, sen_experiment)\n",
    "        andre_labels.extend(labels_a)\n",
    "        sen_labels.extend(labels_b)\n",
    "\n",
    "    assert len(andre_labels) == len(sen_labels), f\"Number of bugs evaluated by Andr and Sen do not match ({len(andre_labels)} vs {len(sen_labels)})\"\n",
    "\n",
    "    kappa = cohen_kappa_score(andre_labels, sen_labels)\n",
    "    print(f\"Number of patches evaluated by both Andr and Sen: {len(andre_labels)}\")\n",
    "    print(f\"Kappa between Andr and Sen: {kappa}\")\n",
    "    print(f\"Raw agreement between Andr and Sen: {sum(1 for a, b in zip(andre_labels, sen_labels) if a == b) / len(andre_labels)}\")\n",
    "\n",
    "compute_kappa(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disagreeing patches evaluated by Martin: 248\n",
      "Kappa between Andr and Sen: -0.8751219512195123\n",
      "Kappa between Andr and Martin: 0.03241296518607428\n",
      "Kappa between Sen and Martin: -0.024793388429751984\n",
      "Raw agreement between Andr and Sen: 0.0\n",
      "Raw agreement between Andr and Martin: 0.5806451612903226\n",
      "Raw agreement between Sen and Martin: 0.41935483870967744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def get_bug_labels_martin_pass(bug):\n",
    "    labels = []\n",
    "    if \"evaluation\" in bug and bug[\"evaluation\"] != None:\n",
    "        # Skip bugs that were not evaluated\n",
    "        if any(x[\"exact_match\"] or x[\"ast_match\"] for x in bug[\"evaluation\"]) or not any(x[\"test\"] for x in bug[\"evaluation\"]):\n",
    "            return labels\n",
    "\n",
    "        for i, evaluation in enumerate(bug[\"evaluation\"]):\n",
    "            # Skip if the patch is not plausible\n",
    "            if not evaluation[\"test\"]:\n",
    "                continue\n",
    "\n",
    "            # Skip those that are still disagree, which means Martin did not evaluate\n",
    "            if evaluation[\"semantical_match\"] == \"Disagree\":\n",
    "                continue\n",
    "\n",
    "            if evaluation[\"semantical_match\"] == True:\n",
    "                labels.append((i, True))\n",
    "                break\n",
    "\n",
    "            labels.append((i, evaluation[\"semantical_match\"]))\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def get_labels_second_pass(exp_a, exp_b, exp_c):\n",
    "    # Sort bugs by bug-id so we get the same order of labels for everyone\n",
    "    exp_a = sorted(exp_a, key=lambda x: x[\"identifier\"])\n",
    "    exp_b = sorted(exp_b, key=lambda x: x[\"identifier\"])\n",
    "    exp_c = sorted(exp_c, key=lambda x: x[\"identifier\"])\n",
    "\n",
    "    # Ensure they have the same bugs\n",
    "    assert len(exp_a) == len(exp_b) == len(exp_c), f\"Number of bugs do not match ({len(exp_a)} vs {len(exp_b)} vs {len(exp_c)})\"\n",
    "    assert all(a[\"identifier\"] == b[\"identifier\"] == c[\"identifier\"] for a, b, c in zip(exp_a, exp_b, exp_c))\n",
    "\n",
    "    labels_a = []\n",
    "    labels_b = []\n",
    "    labels_c = []\n",
    "    for bug_a, bug_b, bug_c in zip(exp_a, exp_b, exp_c):\n",
    "        labels_bug_a = get_bug_labels_first_pass(bug_a)\n",
    "        labels_bug_b = get_bug_labels_first_pass(bug_b)\n",
    "        labels_bug_c = get_bug_labels_martin_pass(bug_c)\n",
    "        # HACK: same as above, plus we only keep those which have different labels in Andr and Sen's eval round\n",
    "        labels_bug_b = [b for b in labels_bug_b if b[0] in [a[0] for a in labels_bug_a] and b[0] in [c[0] for c in labels_bug_c] and b[1] != {a[0]: a[1] for a in labels_bug_a}[b[0]]]\n",
    "        labels_bug_a = [a for a in labels_bug_a if a[0] in [b[0] for b in labels_bug_b]]\n",
    "        labels_bug_c = [c for c in labels_bug_c if c[0] in [a[0] for a in labels_bug_a]]\n",
    "\n",
    "        # Extend\n",
    "        labels_a.extend([a[1] for a in labels_bug_a])\n",
    "        labels_b.extend([b[1] for b in labels_bug_b])\n",
    "        labels_c.extend([c[1] for c in labels_bug_c])\n",
    "\n",
    "    return labels_a, labels_b, labels_c\n",
    "\n",
    "def compute_kappa(experiments):\n",
    "    andre_labels = []\n",
    "    sen_labels = []\n",
    "    martin_labels = []\n",
    "\n",
    "    for experiment, andre_experiment, sen_experiment, martin_experiment in experiments:\n",
    "        # print(f\"Computing kappa for {experiment}\")\n",
    "        labels_a, labels_b, labels_c = get_labels_second_pass(andre_experiment, sen_experiment, martin_experiment)\n",
    "        andre_labels.extend(labels_a)\n",
    "        sen_labels.extend(labels_b)\n",
    "        martin_labels.extend(labels_c)\n",
    "\n",
    "    assert len(andre_labels) == len(sen_labels), f\"Number of bugs evaluated by Andr and Sen do not match ({len(andre_labels)} vs {len(sen_labels)})\"\n",
    "    assert len(andre_labels) == len(martin_labels), f\"Number of bugs evaluated by Andr and Martin do not match ({len(andre_labels)} vs {len(martin_labels)})\"\n",
    "    assert len(sen_labels) == len(martin_labels), f\"Number of bugs evaluated by Sen and Martin do not match ({len(sen_labels)} vs {len(martin_labels)})\"\n",
    "\n",
    "    kappa_andre_sen = cohen_kappa_score(andre_labels, sen_labels, labels=[True, False])\n",
    "    kappa_andre_martin = cohen_kappa_score(andre_labels, martin_labels, labels=[True, False])\n",
    "    kappa_sen_martin = cohen_kappa_score(sen_labels, martin_labels, labels=[True, False])\n",
    "    print(f\"Number of disagreeing patches evaluated by Martin: {len(andre_labels)}\")\n",
    "    print(f\"Kappa between Andr and Sen: {kappa_andre_sen}\")\n",
    "    print(f\"Kappa between Andr and Martin: {kappa_andre_martin}\")\n",
    "    print(f\"Kappa between Sen and Martin: {kappa_sen_martin}\")\n",
    "\n",
    "    print(f\"Raw agreement between Andr and Sen: {sum(a == b for a, b in zip(andre_labels, sen_labels)) / len(andre_labels)}\")\n",
    "    print(f\"Raw agreement between Andr and Martin: {sum(a == b for a, b in zip(andre_labels, martin_labels)) / len(andre_labels)}\")\n",
    "    print(f\"Raw agreement between Sen and Martin: {sum(a == b for a, b in zip(sen_labels, martin_labels)) / len(andre_labels)}\")\n",
    "\n",
    "compute_kappa(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: evaluation_defects4j_repairllama_ir4_or2_martin\n",
      "Number of correct multi-loc bugs: 35\n",
      "Chart-26\n",
      "Chart-4\n",
      "Chart-7\n",
      "Closure-101\n",
      "Closure-102\n",
      "Closure-115\n",
      "Closure-124\n",
      "Closure-128\n",
      "Closure-13\n",
      "Compress-32\n",
      "Compress-44\n",
      "Compress-45\n",
      "Compress-7\n",
      "Csv-5\n",
      "Csv-6\n",
      "Gson-16\n",
      "Gson-6\n",
      "JacksonDatabind-24\n",
      "JacksonDatabind-47\n",
      "JacksonDatabind-49\n",
      "JacksonDatabind-54\n",
      "JacksonDatabind-67\n",
      "JacksonDatabind-83\n",
      "Jsoup-49\n",
      "Jsoup-6\n",
      "Jsoup-64\n",
      "Jsoup-80\n",
      "Jsoup-85\n",
      "Lang-10\n",
      "Math-3\n",
      "Math-72\n",
      "Math-79\n",
      "Math-8\n",
      "Math-86\n",
      "Math-95\n",
      "Experiment: evaluation_humanevaljava_repairllama_ir4_or2_martin\n",
      "Number of correct multi-loc bugs: 13\n",
      "ANTI_SHUFFLE\n",
      "CORRECT_BRACKETING\n",
      "COUNT_UP_TO\n",
      "FLIP_CASE\n",
      "GREATEST_COMMON_DIVISOR\n",
      "IS_PALINDROME\n",
      "LARGEST_SMALLEST_INTEGERS\n",
      "MODP\n",
      "NUMERICAL_LETTER_GRADE\n",
      "RESCALE_TO_UNIT\n",
      "SORT_ARRAY\n",
      "STRONGEST_EXTENSION\n",
      "X_OR_Y\n"
     ]
    }
   ],
   "source": [
    "def print_multi_loc_bugs():\n",
    "    multi_loc_bugs = read_multi_loc_bugs(\"multi-loc-bugs.txt\")\n",
    "    experiments = []\n",
    "    for file_path in Path(\"../../results/3_martin\").glob(\"*.jsonl\"):\n",
    "        if \"ir4_or2\" in file_path.stem:\n",
    "            experiments.append((file_path.stem, read_jsonl_file(file_path)))\n",
    "\n",
    "    for file_path, bugs in experiments:\n",
    "        print(f\"Experiment: {file_path}\")\n",
    "        correct_multi_loc = list(bug for bug in bugs if \"evaluation\" in bug and bug[\"evaluation\"] != None and bug[\"identifier\"] in multi_loc_bugs and (\n",
    "           any(\"semantical_match\" in patch and patch[\"semantical_match\"] == True for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"exact_match\"] for patch in bug[\"evaluation\"])\n",
    "        or any(patch[\"ast_match\"] for patch in bug[\"evaluation\"])\n",
    "        ))\n",
    "        print(f\"Number of correct multi-loc bugs: {len(correct_multi_loc)}\")\n",
    "        for bug in sorted(correct_multi_loc, key=lambda x: x[\"identifier\"]):\n",
    "            print(f\"{bug['identifier']}\")\n",
    "\n",
    "print_multi_loc_bugs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
