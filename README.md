# RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair

If you use RepairLLaMA in academic research, please cite "[RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair](http://arxiv.org/abs/2312.15698)", Technical report, arXiv 2312.15698, 2023. 

```bibtex
@techreport{repairllama2023,
  title={RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair},
  author={Silva, Andr{\'e} and Fang, Sen and Monperrus, Martin},
  url = {http://arxiv.org/abs/2312.15698},
  number = {2312.15698},
  institution = {arXiv},
}
```

This repository contains the code, model, and results to replicate the paper "RepairLLaMA: Efficient Representations and Fine-Tuned Adapters for Program Repair"

It is structured as follows:
- [repair-lora](repair-lora) contains the RepairLLaMA low-rank adaptation of CodeLLaMA-7B, called "repair adapter"
- [results](results) contains all generated patches for Defects4J and HumanEval-Java by all models (incl. full fine-tuning, lora, and code representations)
- [src](src) contains the training and inference scripts

The processed fine-tuning datasets, as well as all models, are made available on HuggingFace.

For further research, we manually analyzed the plausible patches generated by our best code representation, see [humaneval-manual](https://github.com/ASSERT-KTH/repairllama/tree/main/results/humanevaljava/repairllama/lora/manual_analysis) and [defects4j-manual](https://github.com/ASSERT-KTH/repairllama/tree/main/results/defects4j/repairllama/lora/manual_analysis).
